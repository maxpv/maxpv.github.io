{"cells":[{"metadata":{"_cell_guid":"2915b231-58cd-49d3-9ccf-8dc41a406322","_uuid":"92e76e4d30d38afe0467c0dd78d753d811116baf"},"cell_type":"markdown","source":"[Suitability of Dysphonia Measurements for Telemonitoring of Parkinson's Disease](ieeexplore.ieee.org/document/4636708/) :\n\n> Parkinsonâ€™s disease affects over one million people in North America alone. Moreover, an aging population means this number is expected to rise as studies suggest rapidly increasing prevalence rates after the age of 60.\n\n---\n\n> Research has shown that approximately 90% of people with Parkinson exhibit some form of vocal impairment. Vocal impairment may also be one of the earliest indicators for the onset of the illness, and the measurement of voice is noninvasive and simple to administer"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n\ndata_root = '../input/'\ndf = pd.read_csv(data_root+'parkinsons_updrs.data')\nprint(df.shape)\nprint(df.columns)\ndf.head(5)","execution_count":29,"outputs":[]},{"metadata":{"_cell_guid":"83a3c17b-7fc4-49aa-94e5-f5002e087704","_kg_hide-input":true,"_uuid":"f7131d5401cfb92ca8471b3a567adf44e74437ce","trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1,1)\ndf[\"motor_UPDRS\"].plot(kind=\"density\")\ndf[\"total_UPDRS\"].plot(kind=\"density\")\nfig.show()","execution_count":30,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_kg_hide-input":true,"_kg_hide-output":false,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"male = len(df[df['sex'] == 0])\nfemale = len(df[df['sex'] == 1])\nprint(\"There is {0} males and {1} females.\".format(male, female))","execution_count":31,"outputs":[]},{"metadata":{"_cell_guid":"cb7d1665-9ebc-46b9-882b-7bf73d42e99f","_kg_hide-input":true,"_uuid":"f7aade4224683879ba7fc1efebf9888cd5ee3664","trusted":true},"cell_type":"code","source":"def corr_sub_plot(ax, df, title=\"\"):\n    corr = df.corr()\n    avg_corr = np.absolute(corr.values[np.triu_indices_from(corr.values,1)]).mean()\n    ax.set_title(title+\" (abs(average)={0:.4})\".format(avg_corr))\n    ax.set_xticks(np.arange(len(df.columns)))\n    ax.set_yticks(np.arange(len(df.columns)))\n    ax.set_yticklabels(df.columns)\n    ax.set_xticklabels(df.columns)\n    return ax.imshow(corr, interpolation=\"nearest\", cmap='cool', vmin=-1, vmax=1)\n\nfig, ax = plt.subplots()\ncax = corr_sub_plot(ax, df.iloc[:,17:], title=\"Correlation plot \")\nfig.colorbar(cax);","execution_count":32,"outputs":[]},{"metadata":{"_cell_guid":"fac54609-2cf6-4a5e-bbdb-9e6fb9ed2ffa","_uuid":"a769bd71e1d7ae28e417558b723d9b4d99919e93"},"cell_type":"markdown","source":"High negative correlaton between HNR and the other selected variables.\n\nAccording to [this paper](https://ac.els-cdn.com/S2212017313002788/1-s2.0-S2212017313002788-main.pdf?_tid=0de263ce-372c-4c8f-853b-a19fddab2c8a&acdnat=1522157229_8b968085b447433a596a42663e1b4316): `HNR = 10 * log_10(Energy_in_periodic_part/Energy_in_noise)`\n\n Voice quality can be dertermined using such a measure [(source)](http://www.fon.hum.uva.nl/praat/manual/Harmonicity.html):\n\n>a healthy speaker can produce a sustained [a] or [i] with a harmonicity of around 20 dB, and an [u] at around 40 dB; the difference comes from the high frequencies in [a] and [i], versus low frequencies in [u], resulting in a much higher sensitivity of HNR to jitter in [a] and [i] than in [u]. Hoarse speakers will have an [a] with a harmonicity much lower than 20 dB. We know of a pathological case where a speaker had an HNR of 40 dB for [i], because his voice let down above 2000 Hz. \n\nSince usually men and women's voices lies in different fundamental frequencies we can probably find something. Those scatter plots may help us:"},{"metadata":{"_cell_guid":"00674779-c730-4434-8b0c-b45e2c6a96f5","_kg_hide-input":false,"_uuid":"c0df784083a4356e9ff2502b2871ceb6cbbff60e","scrolled":true,"trusted":true},"cell_type":"code","source":"from itertools import combinations\ndef scatter_patient(df, subject_list, columns, patient_filter, scatter_alpha=0.3):\n    fig, ax = plt.subplots(figsize=(30,22))\n    f = [comb for comb in combinations(range(len(columns)), 2)]\n    \n    for _, fp, _ in patient_filter:\n        fp = fp & subject_list\n        \n    for i in range(len(f)):\n        plt.subplot(5,5,i + 1)\n        column_1 = columns[f[i][0]]\n        column_2 = columns[f[i][1]]\n        \n        for name, fp, color in patient_filter:\n            plt.scatter(df[fp][column_1], df[fp][column_2], alpha=scatter_alpha, marker='.', color=color, s=5, label=name)\n        \n        plt.xlabel(column_1)\n        plt.ylabel(column_2)\n        if(i == 0 or i == len(f)):\n            plt.legend(markerscale=5, framealpha=1)\n\n\nsex_filter_patient = [('Men', df['sex'] == 0, 'red'), \n                      ('Women', df['sex'] == 1, 'black')]\nscatter_patient(df, df['subject#'] == df['subject#'], ['NHR', 'HNR', 'PPE', 'DFA', 'RPDE'], sex_filter_patient)","execution_count":33,"outputs":[]},{"metadata":{"_cell_guid":"86e67d45-314b-4198-bafb-ad5f066d4534","_uuid":"b899f1ed2d71edb68697715d42c518f924d7385d"},"cell_type":"markdown","source":"In the end apparently not much difference. Women, even if represented twice less than men, tends to have more spreaded values.\n\nUsing the same representation we can have a look at age. "},{"metadata":{"_cell_guid":"7a3b22c4-3064-4891-bc78-265c9e8c9144","_kg_hide-input":true,"_uuid":"e4ba11ca6ca5d36bf0df58a4c042adea30f2fe72","trusted":true},"cell_type":"code","source":"pd.DataFrame(df.age).plot(kind=\"density\");","execution_count":34,"outputs":[]},{"metadata":{"_cell_guid":"661dba5b-d830-4192-9889-c33b58a41ff4","_kg_hide-input":true,"_uuid":"5fd2d0ce6d05c72d11e15313214451de0a9dc5d2","trusted":true},"cell_type":"code","source":"low_margin = 66\nless = df['age'] <= low_margin\nmore = df['age'] > low_margin\n\nage_filter_patient = [('Age<{}'.format(low_margin), less, 'green'), \n                      ('{}>Age'.format(low_margin), more, 'black')]\nscatter_patient(df, True, ['NHR', 'HNR', 'PPE', 'DFA', 'RPDE'], age_filter_patient, scatter_alpha=0.3)","execution_count":35,"outputs":[]},{"metadata":{"_cell_guid":"71f98718-ec59-42cd-bea0-eb035d065913","_uuid":"7d8f3f2e4d48cd34b02d6eac90d50c725b76a5c3"},"cell_type":"markdown","source":"Pipelining and modeling the regression."},{"metadata":{"_cell_guid":"1d0c6368-75dd-4eba-988b-ea2604f85746","_uuid":"bf3db6cd10f81e391bf56426ecc56d08dda7c835","trusted":true},"cell_type":"code","source":"from sklearn.pipeline import Pipeline, make_pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.decomposition import PCA\n\nnumerical = ['Jitter(%)', 'Jitter(Abs)','Jitter:RAP','Jitter:PPQ5','Jitter:DDP',\n            'Shimmer','Shimmer(dB)','Shimmer:APQ3','Shimmer:APQ5','Shimmer:APQ11','Shimmer:DDA',\n            'NHR', 'HNR', 'RPDE', 'DFA', 'PPE', 'age', 'sex', 'test_time']\n\nfeatures_pipe = make_pipeline(StandardScaler(), PCA(n_components=0.95))\ntargets_pipe = make_pipeline(StandardScaler())\n\nX = features_pipe.fit_transform(df[numerical])\n\ntargets = df[['motor_UPDRS', 'total_UPDRS']]\ny = targets_pipe.fit_transform(targets)\n\ninput_width = X.shape[1]\nprint(input_width)","execution_count":36,"outputs":[]},{"metadata":{"_cell_guid":"4eb31276-6a3f-4daa-8e27-e51ac7caf6be","_uuid":"7e0a6a74781ce750b3ea3d1fb16fc5f41e727965","trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, stratify = df['subject#'], train_size=0.9, random_state=4422)\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=4422)","execution_count":37,"outputs":[]},{"metadata":{"_cell_guid":"43b9005a-cc4f-4886-9324-cbf4aba21f0a","_uuid":"2e39c070e6f31e2e3bb486e293957f29416bf0b2","trusted":true,"collapsed":true},"cell_type":"code","source":"import keras\nfrom keras.callbacks import EarlyStopping\n\nfrom IPython.display import clear_output\nfrom mpl_toolkits.axes_grid1.inset_locator import zoomed_inset_axes \nfrom mpl_toolkits.axes_grid1.inset_locator import mark_inset\n\nearlystop = EarlyStopping(monitor='val_loss', min_delta=0.005, patience=200, verbose=1, mode='min')\n\n# forked from: gist.github.com/stared/dfb4dfaf6d9a8501cd1cc8b8cb806d2e\nclass PlotLosses(keras.callbacks.Callback):\n    def __init__(self, skip=5, refresh_rate=5, figsize=(17,10), zoom_delta=7):\n        self.skip = skip\n        self.refresh_rate= refresh_rate\n        self.figsize=figsize\n        self.fig = plt.figure()\n        self.zoom_delta = zoom_delta\n        \n    def on_train_begin(self, logs={}):\n        self.i = 0\n        self.x = []\n        self.losses = []\n        self.val_losses = []\n\n        self.logs = []\n\n    def on_epoch_end(self, epoch, logs={}):\n        last_loss = logs.get('loss')\n        last_val_loss = logs.get('val_loss')\n\n        self.x.append(self.i)\n        self.losses.append(last_loss)\n        self.val_losses.append(last_val_loss)\n        self.i += 1\n        \n        if(self.i % self.refresh_rate == 0 and self.i > self.skip):\n            clear_output(wait=True)\n            fig = plt.figure(figsize=self.figsize)\n            ax = fig.add_subplot(2, 1, 1)\n            ax.plot(self.x[self.skip:], self.losses[self.skip:], label=\"loss\");\n            ax.plot(self.x[self.skip:], self.val_losses[self.skip:], label=\"val_loss\");\n            plt.title(\"{0:.4} loss & {1:.4} validation loss (epoch={2})\".format(last_loss, last_val_loss, self.i))\n            plt.legend()\n            \n            if(self.i > 100):\n                zoom = min(int(self.i/300) + 1, 4)\n                axins = zoomed_inset_axes(ax, zoom, loc=7)\n                last_epochs = slice(self.i-self.zoom_delta-1,self.i-1)\n                min_y = min(min(self.losses[last_epochs]), min(self.val_losses[last_epochs]))\n                max_y =  max(max(self.losses[last_epochs]), max(self.val_losses[last_epochs]))\n                if(max_y - min_y < 0.2):\n                    max_y += 0.04/zoom\n                    min_y -= 0.04/zoom\n                \n                axins.plot(self.x[self.skip:], self.losses[self.skip:])\n                axins.plot(self.x[self.skip:], self.val_losses[self.skip:])\n                axins.set_xlim(last_epochs.start, last_epochs.stop)\n                axins.set_ylim(min_y, max_y)\n                mark_inset(ax, axins, loc1=3, loc2=4, fc=\"none\", ec=\"0.5\")\n\n            plt.show()","execution_count":38,"outputs":[]},{"metadata":{"_cell_guid":"64a34b2a-1d2d-4d1c-96ef-24100f1c0151","_uuid":"b4fb361b216e2757256f63b01a530705d2c5e7b3","trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense, Activation, Dropout, BatchNormalization\n\nplot_losses = PlotLosses()\n\ndef make_fully_connected_regressor(neuron_per_layers, input_shape):\n    model = Sequential([\n        Dense(neuron_per_layers, input_shape=input_shape, kernel_initializer='he_uniform', activation='relu'),\n        BatchNormalization(),\n        Dropout(0.4),\n        Dense(neuron_per_layers, kernel_initializer='he_uniform', activation='relu'),\n        BatchNormalization(),\n        Dropout(0.2),\n        Dense(neuron_per_layers, kernel_initializer='he_uniform', activation='relu'),\n        BatchNormalization(),\n        Dense(2, kernel_initializer='he_uniform', activation='linear'),\n    ])\n    model.compile(optimizer='adam', loss='mean_squared_error')\n    return model","execution_count":56,"outputs":[]},{"metadata":{"_cell_guid":"de767e32-ff49-4879-a05d-f2d292ac830b","_uuid":"28989f0f0eda3bd08581987529a1f4dfb5e4a43e","scrolled":true,"trusted":true},"cell_type":"code","source":"model = make_fully_connected_regressor(neuron_per_layers=105, input_shape=(input_width,))\n\nmodel.fit(X_train, y_train, epochs=2000, batch_size=256, verbose=0, validation_data=(X_val, y_val), callbacks=[earlystop, plot_losses])\nmodel.save('model_1.h5')","execution_count":52,"outputs":[]},{"metadata":{"_cell_guid":"6b3c6b14-52e6-46b7-92c2-be358bc6b97e","_uuid":"25d2afc4e45b9ba19539fdb08f7624a1f7bbf3e9"},"cell_type":"markdown","source":"Let's compute the mean squarred errors on the inverse transformed output on the test set."},{"metadata":{"_cell_guid":"aadf3270-f650-4348-a424-9fc4156fe9ef","_uuid":"aa7de7cf62e28942e1b4128cbd93524cb0052886","scrolled":true,"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\n\ntest_predictions = model.predict(X_test)\ninversed_test_labels = targets_pipe.inverse_transform(y_test)\ninversed_predictions = targets_pipe.inverse_transform(test_predictions)\n\nmotor_UPDRS_se = mean_squared_error(inversed_test_labels[:,0], inversed_predictions[:,0])\ntotal_UPDRS_se = mean_squared_error(inversed_test_labels[:,1], inversed_predictions[:,1])\n\nmotor_UPDRS_se, total_UPDRS_se","execution_count":28,"outputs":[]},{"metadata":{"_cell_guid":"17f3c1bf-3348-4a4c-ba99-c06819ab5958","_uuid":"ce8cb7f253b608704238403d0e1230a40793d603","collapsed":true},"cell_type":"markdown","source":"Let's try to blindly search for new features."},{"metadata":{"_cell_guid":"81259fcb-447b-4152-858d-2e6df2506ad1","_uuid":"3250ddb067da2323071764c8ebef7000b6c07d59","trusted":true},"cell_type":"code","source":"transforms = [np.exp, np.log, np.tanh, np.power, np.sqrt]\n\nfor e in numerical:\n    ref_motor = abs(np.corrcoef(df[e], df['motor_UPDRS'])).mean()\n    ref_total = abs(np.corrcoef(df[e], df['total_UPDRS'])).mean()\n    print(\"Current column={0}\".format(e))\n    \n    for t in transforms:\n        transformed = 0\n        if t is np.power:\n            transformed = t(df[e],2)\n        else:\n            transformed = t(df[e])\n            \n        motor = abs(np.corrcoef(transformed, df['motor_UPDRS'])).mean()\n        total = abs(np.corrcoef(transformed, df['total_UPDRS'])).mean()\n        \n        if(motor >= ref_motor + 0.01):\n            diff = motor - ref_motor\n            print(\"transformer={0} enhance correlation for motor_UPDRS (+{1:.4} +{2:.4})\".format(t, motor - ref_motor, ((ref_motor+diff)/ref_motor - 1)*100))\n        if(total >= ref_total + 0.01):\n            diff = total - ref_total\n            print(\"transformer={0} enhance correlation for total_UPDRS (+{1:.4} +{2:.4}%)\".format(t, total - ref_total, ((ref_total+diff)/ref_total - 1)*100))","execution_count":40,"outputs":[]},{"metadata":{"_cell_guid":"d6e2d061-e9b4-42eb-9afc-39f3fb0e7bbe","_uuid":"77260b4a97c13a6d7ba0d60f5d41126360d862bc","collapsed":true,"trusted":true},"cell_type":"code","source":"to_log = ['Jitter(%)', 'Jitter(Abs)','Jitter:RAP','Jitter:PPQ5','Jitter:DDP','Shimmer','Shimmer(dB)','Shimmer:APQ3','Shimmer:APQ5','Shimmer:APQ11','Shimmer:DDA','NHR']\nfor feature in to_log:\n    df[feature+'_log'] = np.log(df[feature])\n    \ndf['HNR_sq'] = np.power(df['HNR'],2)","execution_count":45,"outputs":[]},{"metadata":{"_cell_guid":"1b6d6e3d-7ebb-44fb-83cc-7e1ed6d5bdd8","_uuid":"cc8e352697709a43aee89175bd0f45e39905345f","trusted":true},"cell_type":"code","source":"numerical_v2 = ['Jitter(%)_log', 'Jitter(Abs)_log','Jitter:RAP_log','Jitter:PPQ5_log','Jitter:DDP_log',\n            'Shimmer_log','Shimmer(dB)_log','Shimmer:APQ3_log','Shimmer:APQ5_log','Shimmer:APQ11_log','Shimmer:DDA_log',\n            'NHR_log', 'HNR_sq'] + numerical\n\nfeatures_pipe_v2 = make_pipeline(StandardScaler(), PCA(n_components=0.96))\ntargets_pipe_v2 = make_pipeline(StandardScaler())\n\nX2 = features_pipe_v2.fit_transform(df[numerical_v2])\ny2 = targets_pipe_v2.fit_transform(targets)\n\nX2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, train_size=0.9, stratify = df['subject#'], random_state=4422)\nX2_train, X2_val, y2_train, y2_val = train_test_split(X2_train, y2_train, test_size=0.2, random_state=4422)\ninput_width2 = X2.shape[1]\nprint(input_width2)","execution_count":58,"outputs":[]},{"metadata":{"_cell_guid":"9773727e-a7c7-4a81-99b0-3a443f55042f","_uuid":"962f3a5ad66442f5ab1b6a3b0bb3ae36b7b810a7","trusted":true},"cell_type":"code","source":"augmented_model = make_fully_connected_regressor(neuron_per_layers=105, input_shape=(input_width2,))\n\naugmented_model.fit(X2_train, y2_train, epochs=2000, batch_size=256, verbose=0, validation_data=(X2_val, y2_val), callbacks=[earlystop, plot_losses])","execution_count":60,"outputs":[]},{"metadata":{"_cell_guid":"5bcc7f93-dd0b-45a1-b409-4664f555ef57","_uuid":"9b6273965d24fd15650b73c73bc7185bc1fa65b5","trusted":true},"cell_type":"code","source":"test_predictions = augmented_model.predict(X2_test)\ninversed_test_labels = targets_pipe_v2.inverse_transform(y2_test)\ninversed_predictions = targets_pipe_v2.inverse_transform(test_predictions)\n\nmotor_UPDRS_se = mean_squared_error(inversed_test_labels[:,0], inversed_predictions[:,0])\ntotal_UPDRS_se = mean_squared_error(inversed_test_labels[:,1], inversed_predictions[:,1])\n\nmotor_UPDRS_se, total_UPDRS_se","execution_count":61,"outputs":[]},{"metadata":{"_cell_guid":"eea01efc-e487-4d31-a525-23dc24e23036","_uuid":"783dbedfa4d52b019d5bc4c4e5846ca079bb1ada","collapsed":true,"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"0f851b63-a000-4cb5-8803-b954831bdb34","_uuid":"fa0fcef040716e346bde1f5f358d1bba053d79a7","collapsed":true,"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}